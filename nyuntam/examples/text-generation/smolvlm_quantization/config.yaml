# lmquant_quantization.yaml

# Model configuration
MODEL: "smolvlm"
CUSTOM_MODEL_PATH: "/home/azureuser/shwu/vlm_model_smolvlm/weights"

# Data configuration
DATASET_NAME: "vlm_caliberation_dataset"
DATASET_SUBNAME: ""
TEXT_COLUMN: "conversations"
IMAGE_COLUMN: "image_url"                     
SPLIT: "train"
VLM_DATASET: True

DATA_PATH: "/home/azureuser/shwu/vlm_dataset/calibration_dataset"
FORMAT_STRING:

# Quantization configuration
llm:
  LMQuant:
    model.is_vlm: True
    # Quantization parameters
    save_model: True
    keep_scales: True
    loads_with_qserve: False
    dtype: float32

    quant_type: "gchn"
    quant.develop_dtype: torch.float32
    quant.enable_rotation: False
    quant.enable_reorder: False
    quant.enable_smooth: False

    quant.wgts.calib_range.outputs_device: cpu
    quant.reorder.outputs_device: cpu
    quant.post_rotary: False

    # Nested dictionary for quantization parameters
    eval.tasks:
      - arc_challenge:25
    eval.max_seq_length: 4096
    eval.evaluator: "lm_eval"


# Job configuration
CUDA_ID: "0"
ALGORITHM: "LMQuant"
JOB_SERVICE: "Kompress"
USER_FOLDER: "user_data"
JOB_ID: "lmquant_quantization"
CACHE_PATH: "user_data/.cache"
JOB_PATH: "user_data/jobs/lmquant_quantization"
LOGGING_PATH: "user_data/logs/lmquant_quantization"
ALGO_TYPE: "llm"
TASK: "llm"
TRUST_REMOTE_CODE: True